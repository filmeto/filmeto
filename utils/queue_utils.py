# async_queue.py
import asyncio
import threading
import queue
import traceback
from asyncio import Queue, Task
from concurrent.futures import ThreadPoolExecutor
from typing import Callable, Any, Optional, Union, Awaitable
import logging
import time

logger = logging.getLogger(__name__)

class AsyncQueueManager:
    """
    åŸºäº qasync çš„éç­‰å¾…å¼å¼‚æ­¥æ¶ˆè´¹é˜Ÿåˆ—ç®¡ç†å™¨
    ä¸“ä¸º PySide/PyQt è®¾è®¡ï¼Œæ”¯æŒ GUI ä¸»çº¿ç¨‹ä¸­å®‰å…¨è¿è¡Œ asyncio
    """

    def __init__(
        self,
        processor: Callable[[Any], None],
        maxsize: int = 100,
        max_concurrent: int = 1,
        name: str = "AsyncConsumer"
    ):
        """
        :param processor: å¼‚æ­¥å¤„ç†å‡½æ•°ï¼Œç­¾å: async def func(item) -> None
        :param maxsize: é˜Ÿåˆ—æœ€å¤§å®¹é‡
        :param max_concurrent: æœ€å¤§å¹¶å‘æ•°ï¼ˆ1ä¸ºä¸²è¡Œå¤„ç†ï¼Œ>1ä¸ºå¹¶å‘å¤„ç†ï¼‰
        :param name: æ¶ˆè´¹è€…åç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        """
        if not asyncio.iscoroutinefunction(processor):
            raise TypeError("processor å¿…é¡»æ˜¯ä¸€ä¸ª async def å‡½æ•°")

        self.processor = processor
        self.queue = Queue(maxsize=maxsize)
        self.max_concurrent = max_concurrent
        self.name = name
        self._task: Optional[Task] = None
        self._running = False

    def put(self, item: Any):
        """
        éç­‰å¾…å¼æäº¤ä»»åŠ¡ï¼ˆçº¿ç¨‹å®‰å…¨ï¼Œå¯åœ¨ä»»æ„çº¿ç¨‹è°ƒç”¨ï¼‰
        ç«‹å³è¿”å›ï¼Œä¸é˜»å¡ç”Ÿäº§è€…
        """
        if not self._running:
            raise RuntimeError(f"{self.name} å°šæœªå¯åŠ¨ï¼Œè¯·å…ˆè°ƒç”¨ start()")

        # ä½¿ç”¨ asyncio.run_coroutine_threadsafe ç¡®ä¿çº¿ç¨‹å®‰å…¨
        try:
            future = asyncio.run_coroutine_threadsafe(
                self._put_safe(item),
                asyncio.get_event_loop()
            )
            # ä¸ awaitï¼Œç«‹å³è¿”å›
        except Exception as e:
            logger.error(f"âŒ æäº¤ä»»åŠ¡å¤±è´¥ {item}: {e}")

    async def _put_safe(self, item: Any):
        """å®‰å…¨å…¥é˜Ÿï¼ˆé¿å… QueueFullï¼‰"""
        if self.queue.full():
            logger.warning(f"âš ï¸ {self.name} é˜Ÿåˆ—å·²æ»¡ï¼Œä¸¢å¼ƒä»»åŠ¡: {item}")
            return
        self.queue.put_nowait(item)

    async def start(self):
        """å¯åŠ¨æ¶ˆè´¹è€…ï¼ˆå¿…é¡»åœ¨äº‹ä»¶å¾ªç¯ä¸­è°ƒç”¨ï¼‰"""
        if self._running:
            logger.info(f"âš ï¸ {self.name} å·²ç»åœ¨è¿è¡Œä¸­")
            return
        logger.info(f"ğŸ”„ {self.name} å¼€å§‹å¯åŠ¨...")
        self._running = True
        self._task = asyncio.create_task(self._run())  # Python 3.7 compatibility - no name parameter
        logger.info(f"âœ… {self.name} å·²å¯åŠ¨ | å®¹é‡: {self.queue.maxsize} | æœ€å¤§å¹¶å‘æ•°: {self.max_concurrent}")
        # Give a tiny bit of time for the task to actually start
        await asyncio.sleep(0.01)

    async def stop(self):
        """åœæ­¢æ¶ˆè´¹è€…ï¼Œç­‰å¾…å½“å‰ä»»åŠ¡å®Œæˆ"""
        if not self._running:
            return
        # Set running to False to signal the worker to stop accepting new items
        self._running = False
        
        # Wait for the main task to complete naturally or handle cancellation properly
        if self._task:
            try:
                # Wait for the main task to finish processing (it should exit the loop when self._running is False)
                await self._task
            except asyncio.CancelledError:
                # The task was cancelled, which is fine
                pass
        logger.info(f"ğŸ›‘ {self.name} å·²åœæ­¢")

    async def join(self):
        """ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å¤„ç†å®Œæˆ"""
        await self.queue.join()

    async def _run(self):
        """åå°æ¶ˆè´¹å¾ªç¯"""
        try:
            logger.info(f"ğŸŸ¢ {self.name} å¾ªç¯å¼€å§‹ | æœ€å¤§å¹¶å‘æ•°: {self.max_concurrent}")
            
            # å¦‚æœå¹¶å‘æ•°ä¸º1ï¼Œä½¿ç”¨ä¸²è¡Œå¤„ç†
            if self.max_concurrent <= 1:
                logger.info(f"ğŸ”µ {self.name} ä½¿ç”¨ä¸²è¡Œå¤„ç†æ¨¡å¼")
                while True:  # ä¸ä»…æ£€æŸ¥ self._runningï¼Œè¿˜è¦å¤„ç†é˜Ÿåˆ—ä¸­å‰©ä½™çš„ä»»åŠ¡
                    try:
                        # å½“ running ä¸º False ä¸”é˜Ÿåˆ—ä¸ºç©ºæ—¶ï¼Œé€€å‡ºå¾ªç¯
                        if not self._running and self.queue.empty():
                            logger.info(f"ğŸŸ¡ {self.name} é€€å‡ºæ¡ä»¶: _running=False ä¸”é˜Ÿåˆ—ä¸ºç©º")
                            break
                        item = await self.queue.get()
                        logger.info(f"ğŸ“¦ {self.name} è·å–åˆ°é¡¹ç›®: {item}")
                        try:
                            await self.processor(item)
                            logger.info(f"âœ… {self.name} å¤„ç†å®Œæˆ: {item}")
                        except Exception as e:
                            logger.error(f"âŒ {self.name} å¤„ç†å¤±è´¥ {item}: {e}", exc_info=True)
                        finally:
                            self.queue.task_done()
                            logger.info(f"âœ… {self.name} task_done è°ƒç”¨: {item}")
                    except asyncio.CancelledError:
                        logger.info(f"ğŸ›‘ {self.name} è¢«å–æ¶ˆ")
                        break
                    except Exception as e:
                        logger.error(f"âŒ {self.name} å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {e}", exc_info=True)
            else:
                # å¹¶å‘å¤„ç†æ¨¡å¼
                logger.info(f"ğŸ”µ {self.name} ä½¿ç”¨å¹¶å‘å¤„ç†æ¨¡å¼ | å¹¶å‘æ•°: {self.max_concurrent}")
                
                # åˆ›å»ºä¿¡å·é‡æ¥é™åˆ¶å¹¶å‘æ•°
                semaphore = asyncio.Semaphore(self.max_concurrent)
                
                async def process_with_semaphore(item):
                    async with semaphore:
                        try:
                            logger.info(f"ğŸ“¦ {self.name} å¼€å§‹å¤„ç†: {item}")
                            await self.processor(item)
                            logger.info(f"âœ… {self.name} å¤„ç†å®Œæˆ: {item}")
                        except Exception as e:
                            logger.error(f"âŒ {self.name} å¤„ç†å¤±è´¥ {item}: {e}", exc_info=True)
                        finally:
                            self.queue.task_done()
                            logger.info(f"âœ… {self.name} task_done è°ƒç”¨: {item}")
                
                # æŒç»­ä»é˜Ÿåˆ—è·å–ä»»åŠ¡å¹¶æäº¤åˆ°å¹¶å‘æ± 
                # å…ˆå¤„ç†è¿è¡Œæ—¶çš„é¡¹ç›®ï¼Œç„¶åå¤„ç†åœæ­¢åçš„å‰©ä½™é¡¹ç›®
                # Continue until both conditions are met: 
                # 1. We've been asked to stop (self._running is False)
                # 2. Queue is empty
                while not (not self._running and self.queue.empty()):
                    try:
                        # Try to get an item from the queue
                        # Use timeout to periodically check if we should stop
                        try:
                            item = await asyncio.wait_for(self.queue.get(), timeout=0.5)
                            logger.info(f"ğŸ“¦ {self.name} è·å–åˆ°é¡¹ç›®: {item}")
                            # Create a task to process the item concurrently
                            asyncio.create_task(process_with_semaphore(item))
                        except asyncio.TimeoutError:
                            # Timeout occurred, check the stop condition again
                            continue
                    except asyncio.CancelledError:
                        logger.info(f"ğŸ›‘ {self.name} è¢«å–æ¶ˆ")
                        break
                    except Exception as e:
                        logger.error(f"âŒ {self.name} å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {e}", exc_info=True)
                
                # At this point, either we've been asked to stop and queue is empty,
                # or the task was cancelled. Wait for any remaining queue operations to complete.
                logger.info(f"â³ {self.name} ç­‰å¾…é˜Ÿåˆ—ä¸­æ‰€æœ‰ä»»åŠ¡å®Œæˆ")
                await self.queue.join()
                logger.info(f"âœ… {self.name} é˜Ÿåˆ—ä¸­æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆ")
            
            logger.info(f"ğŸ‘‹ {self.name} å¾ªç¯é€€å‡º")
        except Exception as e:
            logger.error(f"âŒ {self.name} _runæ–¹æ³•å‘ç”Ÿæœªé¢„æœŸçš„é¡¶çº§é”™è¯¯: {e}", exc_info=True)
            raise


class SyncQueueManager:
    """
    é˜»å¡å¼åŒæ­¥æ¶ˆè´¹é˜Ÿåˆ—ç®¡ç†å™¨
    æ”¯æŒé˜»å¡å¼æ¶ˆè´¹ä»»åŠ¡ï¼ŒåŒæ—¶å…¼å®¹å¼‚æ­¥ä»»åŠ¡æ‰§è¡Œæ–¹æ³•
    """
    
    def __init__(
        self,
        processor: Union[Callable[[Any], Any], Callable[[Any], Awaitable]],
        maxsize: int = 100,
        max_concurrent: int = 1,
        name: str = "SyncConsumer",
        thread_pool_size: int = 4
    ):
        """
        :param processor: å¤„ç†å‡½æ•°ï¼Œå¯ä»¥æ˜¯åŒæ­¥æˆ–å¼‚æ­¥å‡½æ•°
        :param maxsize: é˜Ÿåˆ—æœ€å¤§å®¹é‡
        :param max_concurrent: æœ€å¤§å¹¶å‘æ•°ï¼ˆ1ä¸ºä¸²è¡Œå¤„ç†ï¼Œ>1ä¸ºå¹¶å‘å¤„ç†ï¼‰
        :param name: æ¶ˆè´¹è€…åç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        :param thread_pool_size: çº¿ç¨‹æ± å¤§å°ï¼Œç”¨äºè¿è¡Œå¼‚æ­¥äº‹ä»¶å¾ªç¯
        """
        self.processor = processor
        self.queue = queue.Queue(maxsize=maxsize)
        self.max_concurrent = max_concurrent
        self.name = name
        self.thread_pool_size = thread_pool_size
        
        self._running = False
        self._worker_threads = []
        self._executor = ThreadPoolExecutor(max_workers=thread_pool_size)
        self._loop = None
        self._loop_thread = None

    def put(self, item: Any, block: bool = True, timeout: Optional[float] = None):
        """
        æäº¤ä»»åŠ¡åˆ°é˜Ÿåˆ—
        
        :param item: è¦å¤„ç†çš„é¡¹ç›®
        :param block: æ˜¯å¦é˜»å¡ç­‰å¾…ï¼ˆå½“é˜Ÿåˆ—æ»¡æ—¶ï¼‰
        :param timeout: è¶…æ—¶æ—¶é—´
        """
        if not self._running:
            raise RuntimeError(f"{self.name} å°šæœªå¯åŠ¨ï¼Œè¯·å…ˆè°ƒç”¨ start()")
        
        self.queue.put(item, block=block, timeout=timeout)
        logger.info(f"ğŸ“¦ {self.name} ä»»åŠ¡å·²æäº¤: {item}")

    def start(self):
        """å¯åŠ¨æ¶ˆè´¹è€…"""
        if self._running:
            logger.info(f"âš ï¸ {self.name} å·²ç»åœ¨è¿è¡Œä¸­")
            return
        
        logger.info(f"ğŸ”„ {self.name} å¼€å§‹å¯åŠ¨...")
        self._running = True
        
        # Start the asyncio event loop in a separate thread
        self._loop = asyncio.new_event_loop()
        self._loop_thread = threading.Thread(target=self._run_event_loop, args=(self._loop,), daemon=True)
        self._loop_thread.start()
        
        # Wait for the event loop to be ready
        time.sleep(0.01)
        
        # Start worker threads based on concurrency setting
        if self.max_concurrent <= 1:
            # Serial processing: start one worker
            worker = threading.Thread(target=self._serial_worker, daemon=True)
            worker.start()
            self._worker_threads = [worker]
            logger.info(f"âœ… {self.name} å·²å¯åŠ¨ | æ¨¡å¼: ä¸²è¡Œ | å®¹é‡: {self.queue.maxsize}")
        else:
            # Concurrent processing: start multiple workers
            self._worker_threads = []
            for i in range(min(self.max_concurrent, self.thread_pool_size)):
                worker = threading.Thread(target=self._concurrent_worker, daemon=True)
                worker.start()
                self._worker_threads.append(worker)
            logger.info(f"âœ… {self.name} å·²å¯åŠ¨ | æ¨¡å¼: å¹¶å‘ | å®¹é‡: {self.queue.maxsize} | å¹¶å‘æ•°: {self.max_concurrent}")

    def stop(self):
        """åœæ­¢æ¶ˆè´¹è€…ï¼Œç­‰å¾…å½“å‰ä»»åŠ¡å®Œæˆ"""
        if not self._running:
            return
        
        logger.info(f"ğŸ›‘ {self.name} å‡†å¤‡åœæ­¢...")
        self._running = False
        
        # Wait for all worker threads to finish
        for worker_thread in self._worker_threads:
            worker_thread.join(timeout=5.0)  # Wait up to 5 seconds for each thread
        
        # Shutdown the executor
        self._executor.shutdown(wait=True, timeout=5.0)
        
        # Stop the event loop thread
        if self._loop and self._loop.is_running():
            asyncio.run_coroutine_threadsafe(self._stop_event_loop(), self._loop)
        
        if self._loop_thread:
            self._loop_thread.join(timeout=5.0)
        
        logger.info(f"ğŸ›‘ {self.name} å·²åœæ­¢")

    def join(self):
        """ç­‰å¾…é˜Ÿåˆ—ä¸­æ‰€æœ‰ä»»åŠ¡å¤„ç†å®Œæˆ"""
        self.queue.join()

    def _run_event_loop(self, loop):
        """åœ¨å•ç‹¬çš„çº¿ç¨‹ä¸­è¿è¡Œ asyncio äº‹ä»¶å¾ªç¯"""
        asyncio.set_event_loop(loop)
        loop.run_forever()

    async def _stop_event_loop(self):
        """åœæ­¢äº‹ä»¶å¾ªç¯"""
        # Cancel all running tasks
        tasks = [task for task in asyncio.all_tasks(self._loop) if not task.done()]
        for task in tasks:
            task.cancel()
        
        # Wait for tasks to finish cancellation
        if tasks:
            await asyncio.gather(*tasks, return_exceptions=True)
        
        # Stop the event loop
        self._loop.call_soon_threadsafe(self._loop.stop)

    def _run_in_event_loop(self, coro):
        """åœ¨äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œåç¨‹"""
        if self._loop and self._loop.is_running():
            future = asyncio.run_coroutine_threadsafe(coro, self._loop)
            return future.result()  # This will block until the coroutine completes
        else:
            # Fallback: run in a new event loop
            return asyncio.run(coro)

    def _serial_worker(self):
        """ä¸²è¡Œå·¥ä½œçº¿ç¨‹"""
        logger.info(f"ğŸŸ¢ {self.name} ä¸²è¡Œå·¥ä½œçº¿ç¨‹å¯åŠ¨")
        
        while self._running or not self.queue.empty():
            try:
                # Get item from queue with timeout to periodically check if still running
                try:
                    item = self.queue.get(timeout=0.5)
                except queue.Empty:
                    continue  # Check the running condition again
                
                logger.info(f"ğŸ“¦ {self.name} è·å–åˆ°é¡¹ç›®: {item}")
                
                # Process the item
                self._process_item(item)
                
                # Mark task as done
                self.queue.task_done()
                logger.info(f"âœ… {self.name} ä»»åŠ¡å®Œæˆ: {item}")
                
            except Exception as e:
                logger.error(f"âŒ {self.name} å·¥ä½œçº¿ç¨‹å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)

        logger.info(f"ğŸ‘‹ {self.name} ä¸²è¡Œå·¥ä½œçº¿ç¨‹é€€å‡º")

    def _concurrent_worker(self):
        """å¹¶å‘å·¥ä½œçº¿ç¨‹"""
        logger.info(f"ğŸŸ¢ {self.name} å¹¶å‘å·¥ä½œçº¿ç¨‹å¯åŠ¨")
        
        while self._running or not self.queue.empty():
            try:
                # Get item from queue with timeout to periodically check if still running
                try:
                    item = self.queue.get(timeout=0.5)
                except queue.Empty:
                    continue  # Check the running condition again
                
                logger.info(f"ğŸ“¦ {self.name} è·å–åˆ°é¡¹ç›®: {item}")
                
                # Process the item
                self._process_item(item)
                
                # Mark task as done
                self.queue.task_done()
                logger.info(f"âœ… {self.name} ä»»åŠ¡å®Œæˆ: {item}")
                
            except Exception as e:
                logger.error(f"âŒ {self.name} å¹¶å‘å·¥ä½œçº¿ç¨‹å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)

        logger.info(f"ğŸ‘‹ {self.name} å¹¶å‘å·¥ä½œçº¿ç¨‹é€€å‡º")

    def _process_item(self, item: Any):
        """å¤„ç†å•ä¸ªé¡¹ç›®ï¼Œå…¼å®¹åŒæ­¥å’Œå¼‚æ­¥å¤„ç†å™¨"""
        try:
            if asyncio.iscoroutinefunction(self.processor):
                # If processor is async, run it in the event loop
                coro = self.processor(item)
                self._run_in_event_loop(coro)
            else:
                # If processor is sync, run it directly
                self.processor(item)
        except Exception as e:
            logger.error(f"âŒ {self.name} å¤„ç†é¡¹ç›®å¤±è´¥ {item}: {e}", exc_info=True)